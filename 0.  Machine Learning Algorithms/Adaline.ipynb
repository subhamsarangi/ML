{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADAptive LInear NEuron (Adaline)\n",
    "(B. Widrow et al. _Adaptive \"Adaline\" neuron using chemical \"memistors\"_.)\n",
    "\n",
    "It illustrates the key concept of defning and minimizing cost functions, which will lay the groundwork for understanding more advanced machine learning algorithms for classifcation, such as logistic regression and support vector machines, as well as regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference between the Adaline rule (also known as the Widrow-Hoff rule) and Perceptron is that the weights are updated based on a _linear activation function_ rather than a unit step function like in the perceptron. In Adaline, this linear activation function $\\phi(z)$ is simply the identity function of the net input so that $\\phi(w^Tx) = w^Tx$.\n",
    "\n",
    "While the linear activation function is used for learning the weights, a _quantizer_, which is similar to the unit step function that we have seen before, can then be used to predict the class labels,\n",
    "![Adaline](images/adaline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
